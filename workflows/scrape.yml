name: Daily Property Scraper

on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours
  workflow_dispatch:  # Manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install selenium beautifulsoup4 requests
          
      - name: Download ChromeDriver
        run: |
          wget https://chromedriver.chromium.org/download
          # Extract and setup
          
      - name: Run scraper
        run: python scraper_script.py
        
      - name: Commit results
        run: |
          git add properties_cache.json
          git commit -m "Update cached properties"
          git push
